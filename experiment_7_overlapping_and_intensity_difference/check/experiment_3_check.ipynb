{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dda7bc",
   "metadata": {},
   "source": [
    "### Settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6490deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18168f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "mypath = \"/home/basia/Documents/spectroscopy/wassersteinms\"\n",
    "sys.path.insert(0, mypath)\n",
    "import masserstein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547dfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from masserstein import Spectrum, NMRSpectrum, estimate_proportions\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pulp\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab180693",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_coef = 1.9726499999999998"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb7afe",
   "metadata": {},
   "source": [
    "### Checking if spectra are almost equal up to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f289d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = np.loadtxt('mix_compare.csv', delimiter=',')\n",
    "comp0_old = np.loadtxt('comp0_compare.csv', delimiter=',')\n",
    "comp1_old = np.loadtxt('comp1_compare.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1ce91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = np.loadtxt('preprocessed_mix.csv', delimiter=',')\n",
    "comp0_p = np.loadtxt('preprocessed_comp0.csv', delimiter=',')\n",
    "comp1_p = np.loadtxt('preprocessed_comp1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fced34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(mix_old[:,1], mix_p[:,1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad9c832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(comp0_old[:,1], comp0_p[:,1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817d2ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(comp1_old[:,1], comp1_p[:,1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54343240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(comp1_old[:,0], comp0_old[:,0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f6cd622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(mix_old[:-1,0]-mix_old[1:,0], mix_p[:-1,0]-mix_p[1:,0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef43e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(mix_p[:,0], comp0_p[:,0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc959af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seem equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd06e8",
   "metadata": {},
   "source": [
    "### Checking estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9055c4",
   "metadata": {},
   "source": [
    "#### Magnetstein + no shift (i.e. negative frequencies allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7df85749",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = np.loadtxt('preprocessed_mix.csv', delimiter=',')\n",
    "comp0_p = np.loadtxt('preprocessed_comp0.csv', delimiter=',')\n",
    "comp1_p = np.loadtxt('preprocessed_comp1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff47216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = NMRSpectrum(confs=list(zip(mix_p[:,0], mix_p[:,1])))\n",
    "comp0_p = NMRSpectrum(confs=list(zip(comp0_p[:,0], comp0_p[:,1])))\n",
    "comp1_p = NMRSpectrum(confs=list(zip(comp1_p[:,0], comp1_p[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b04754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 63.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(-1.97165, 13.9718, 0), (-1.97165, 13.9718, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 81442.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-2.20165, 14.2018)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 3553368.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.000000000000015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basia/.local/lib/python3.10/site-packages/pulp/pulp.py:1352: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n",
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [03:05<00:00, 185.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983121176726\n",
      "Noise proportion in experimental spectrum: 0.016878823246000003\n",
      "Total explanation: 0.999999999972\n",
      "Noise proportion in combination of theoretical spectra: 0.240669939935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_p, [comp0_p, comp1_p],\n",
    "                                   MTD=0.23, MTD_th=0.02, verbose=True, solver=pulp.GUROBI(msg=False),\n",
    "                                    what_to_compare='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c161aa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24066993993500363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202679ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699609f",
   "metadata": {},
   "source": [
    "#### Old masserstein + shift (i.e. negative frequencies forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ad0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = np.loadtxt('mix_compare.csv', delimiter=',')\n",
    "comp0_old = np.loadtxt('comp0_compare.csv', delimiter=',')\n",
    "comp1_old = np.loadtxt('comp1_compare.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5e14190",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = Spectrum(confs=list(zip(mix_old[:,0], mix_old[:,1])))\n",
    "comp0_old = Spectrum(confs=list(zip(comp0_old[:,0], comp0_old[:,1])))\n",
    "comp1_old = Spectrum(confs=list(zip(comp1_old[:,0], comp1_old[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ca2ca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 60.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(0.0009999999999998899, 15.94445, 0), (0.0009999999999998899, 15.94445, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 94254.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-0.22900000000000012, 16.17445)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 3307597.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.0000000000000153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [02:14<00:00, 134.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983116421074\n",
      "Noise proportion in experimental spectrum: 0.01688357892400004\n",
      "Total explanation: 0.999999999998\n",
      "Noise proportion in combination of theoretical spectra: 0.240673613042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_old, [comp0_old, comp1_old],\n",
    "                                   MTD=0.23, MTD_th=0.02, verbose=True, solver=pulp.GUROBI(msg=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b6e8e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2406736130420037"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9acf25",
   "metadata": {},
   "source": [
    "#### Magnetstein + shift (negative frequencies forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cec535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = np.loadtxt('mix_compare.csv', delimiter=',')\n",
    "comp0_old = np.loadtxt('comp0_compare.csv', delimiter=',')\n",
    "comp1_old = np.loadtxt('comp1_compare.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2a24ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = NMRSpectrum(confs=list(zip(mix_old[:,0], mix_old[:,1])))\n",
    "comp0_old = NMRSpectrum(confs=list(zip(comp0_old[:,0], comp0_old[:,1])))\n",
    "comp1_old = NMRSpectrum(confs=list(zip(comp1_old[:,0], comp1_old[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d709830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(0.0009999999999998899, 15.94445, 0), (0.0009999999999998899, 15.94445, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 32263.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-0.22900000000000012, 16.17445)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 3211715.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.0000000000000153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [02:07<00:00, 127.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983116421074\n",
      "Noise proportion in experimental spectrum: 0.01688357892400004\n",
      "Total explanation: 0.999999999998\n",
      "Noise proportion in combination of theoretical spectra: 0.240673613042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_old, [comp0_old, comp1_old],\n",
    "                                    MTD=0.23, MTD_th=0.02, verbose=True, \n",
    "                                    solver=pulp.GUROBI(msg=False),\n",
    "                                    what_to_compare='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39106c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2406736130420037"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7c0cbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3a663",
   "metadata": {},
   "source": [
    "#### Magnetstein + shift, version with Spectrum (not NMRSpectrum) (negative intensities forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e3a6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = np.loadtxt('mix_compare.csv', delimiter=',')\n",
    "comp0_old = np.loadtxt('comp0_compare.csv', delimiter=',')\n",
    "comp1_old = np.loadtxt('comp1_compare.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9afcc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = Spectrum(confs=list(zip(mix_old[:,0], mix_old[:,1])))\n",
    "comp0_old = Spectrum(confs=list(zip(comp0_old[:,0], comp0_old[:,1])))\n",
    "comp1_old = Spectrum(confs=list(zip(comp1_old[:,0], comp1_old[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "702b1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 61.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(0.0009999999999998899, 15.94445, 0), (0.0009999999999998899, 15.94445, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 86480.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-0.22900000000000012, 16.17445)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 2927487.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.0000000000000153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [02:05<00:00, 125.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983116421074\n",
      "Noise proportion in experimental spectrum: 0.01688357892400004\n",
      "Total explanation: 0.999999999998\n",
      "Noise proportion in combination of theoretical spectra: 0.240673613042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_old, [comp0_old, comp1_old],\n",
    "                                    MTD=0.23, MTD_th=0.02, verbose=True, \n",
    "                                    solver=pulp.GUROBI(msg=False),\n",
    "                                    what_to_compare='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1cfe3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2406736130420037"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9afec6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a01f9",
   "metadata": {},
   "source": [
    "#### Magnetstein + shifted spectra shifted by -shift_coef (negative intensities allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6d3a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = np.loadtxt('mix_compare.csv', delimiter=',')\n",
    "comp0_old = np.loadtxt('comp0_compare.csv', delimiter=',')\n",
    "comp1_old = np.loadtxt('comp1_compare.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3367d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_old = NMRSpectrum(confs=list(zip(mix_old[:,0]-shift_coef, mix_old[:,1])))\n",
    "comp0_old = NMRSpectrum(confs=list(zip(comp0_old[:,0]-shift_coef, comp0_old[:,1])))\n",
    "comp1_old = NMRSpectrum(confs=list(zip(comp1_old[:,0]-shift_coef, comp1_old[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47b29d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 48.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(-1.97165, 13.9718, 0), (-1.97165, 13.9718, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 57456.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-2.20165, 14.2018)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 2167405.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.0000000000000153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [02:11<00:00, 131.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983116421074\n",
      "Noise proportion in experimental spectrum: 0.01688357892400004\n",
      "Total explanation: 0.999999999998\n",
      "Noise proportion in combination of theoretical spectra: 0.240673613042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_old, [comp0_old, comp1_old],\n",
    "                                    MTD=0.23, MTD_th=0.02, verbose=True, \n",
    "                                    solver=pulp.GUROBI(msg=False),\n",
    "                                    what_to_compare='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ed968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2406736130420037"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ab9b5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929726b",
   "metadata": {},
   "source": [
    "#### Old masserstein + nonshifted spectra shifted by + shift coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f4403e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = np.loadtxt('preprocessed_mix.csv', delimiter=',')\n",
    "comp0_p = np.loadtxt('preprocessed_comp0.csv', delimiter=',')\n",
    "comp1_p = np.loadtxt('preprocessed_comp1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23869433",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = Spectrum(confs=list(zip(mix_p[:,0]+shift_coef, mix_p[:,1])))\n",
    "comp0_p = Spectrum(confs=list(zip(comp0_p[:,0]+shift_coef, comp0_p[:,1])))\n",
    "comp1_p = Spectrum(confs=list(zip(comp1_p[:,0]+shift_coef, comp1_p[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbf7f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 62.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(0.0009999999999998899, 15.94445, 0), (0.0009999999999998899, 15.94445, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 90200.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-0.22900000000000012, 16.17445)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 3378974.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.000000000000015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [02:35<00:00, 155.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983116966019\n",
      "Noise proportion in experimental spectrum: 0.016883033985000035\n",
      "Total explanation: 1.0000000000040001\n",
      "Noise proportion in combination of theoretical spectra: 0.240673192144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_p, [comp0_p, comp1_p],\n",
    "                                   MTD=0.23, MTD_th=0.02, verbose=True, solver=pulp.GUROBI(msg=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca6df267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24067319214400362"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c395741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21525d0",
   "metadata": {},
   "source": [
    "#### Final check: spectrum without shift + old magnetstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e6b8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from masserstein import Spectrum\n",
    "import pulp as lp\n",
    "from warnings import warn\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from pulp.apis import LpSolverDefault\n",
    "from masserstein import misc\n",
    "\n",
    "\n",
    "\n",
    "def intensity_generator(confs, mzaxis):\n",
    "        \"\"\"\n",
    "        Generates intensities from spectrum represented as a confs list,\n",
    "        over m/z values from mzaxis.\n",
    "        Assumes mzaxis and confs are sorted and returns consecutive intensities.\n",
    "        \"\"\"\n",
    "        mzaxis_id = 0\n",
    "        mzaxis_len = len(mzaxis)\n",
    "        for mz, intsy in confs:\n",
    "            while mzaxis[mzaxis_id] < mz:\n",
    "                yield 0.\n",
    "                mzaxis_id += 1\n",
    "                if mzaxis_id == mzaxis_len:\n",
    "                    return\n",
    "            if mzaxis[mzaxis_id] == mz:\n",
    "                yield intsy\n",
    "                mzaxis_id += 1\n",
    "                if mzaxis_id == mzaxis_len:\n",
    "                    return\n",
    "        for i in range(mzaxis_id, mzaxis_len):\n",
    "                yield 0.\n",
    "\n",
    "\n",
    "def dualdeconv2(exp_sp, thr_sps, penalty, quiet=True, solver=LpSolverDefault):\n",
    "        \"\"\"\n",
    "        This function solves linear program describing optimal transport of signal between the experimental spectrum\n",
    "        and the list of theoretical (reference) spectra. Additionally, an auxiliary point is introduced in order to\n",
    "        remove noise from the experimental spectrum, as described by Ciach et al., 2020. \n",
    "        _____\n",
    "        Parameters:\n",
    "            exp_sp: Spectrum object\n",
    "                Experimental spectrum.\n",
    "            thr_sp: list of Spectrum objects\n",
    "                List of theoretical (reference) spectra.\n",
    "            penalty: float\n",
    "                Denoising penalty.\n",
    "            solver: \n",
    "                Which solver should be used. In case of problems with the default solver,\n",
    "                pulp.GUROBI() is recommended (note that it requires obtaining a licence).\n",
    "                To see all solvers available at your machine execute: pulp.listSolvers(onlyAvailable=True).\n",
    "        _____\n",
    "        Returns: dict\n",
    "            Dictionary with the following entries:\n",
    "            - probs: List containing proportions of consecutive theoretical (reference) spectra in the experimental\n",
    "            spectrum. Note that they do not have to sum up to 1, because some part of the signal can be noise.\n",
    "            - trash: Amount of noise in the consecutive m/z points of the experimental spectrum.\n",
    "            - fun: Optimal value of the objective function.\n",
    "            - status: Status of the linear program.\n",
    "        \"\"\"\n",
    "        start = time()\n",
    "        exp_confs = exp_sp.confs.copy()\n",
    "        thr_confs = [thr_sp.confs.copy() for thr_sp in thr_sps]\n",
    "\n",
    "        # Normalization check:\n",
    "        assert np.isclose(sum(x[1] for x in exp_confs) , 1), 'Experimental spectrum not normalized'\n",
    "        for i, thrcnf in enumerate(thr_confs):\n",
    "                assert np.isclose(sum(x[1] for x in thrcnf), 1), 'Theoretical spectrum %i not normalized' % i\n",
    "\n",
    "        # Computing a common mass axis for all spectra\n",
    "        exp_confs = [(m, i) for m, i in exp_confs]\n",
    "        thr_confs = [[(m, i) for m, i in cfs] for cfs in thr_confs]\n",
    "        global_mass_axis = set(x[0] for x in exp_confs)\n",
    "        global_mass_axis.update(x[0] for s in thr_confs for x in s)\n",
    "        global_mass_axis = sorted(global_mass_axis)\n",
    "        if not quiet:\n",
    "                print(\"Global mass axis computed\")\n",
    "        n = len(global_mass_axis)\n",
    "        k = len(thr_confs)\n",
    "\n",
    "        # Computing lengths of intervals between mz measurements (l_i variables)\n",
    "        interval_lengths = [global_mass_axis[i+1] - global_mass_axis[i] for i in range(n-1)]\n",
    "        if not quiet:\n",
    "                print(\"Interval lengths computed\")\n",
    "\n",
    "        # linear program:\n",
    "        program = lp.LpProblem('Dual_L1_regression_sparse', lp.LpMaximize)\n",
    "        if not quiet:\n",
    "                print(\"Linear program initialized\")\n",
    "        # variables:\n",
    "        lpVars = []\n",
    "        for i in range(n):\n",
    "                lpVars.append(lp.LpVariable('Z%i' % (i+1), None, penalty, lp.LpContinuous))\n",
    "        ##        # in case one would like to explicitly forbid non-experimental abyss:\n",
    "        ##        if V[i] > 0:\n",
    "        ##            lpVars.append(lp.LpVariable('W%i' % (i+1), None, penalty, lp.LpContinuous))\n",
    "        ##        else:\n",
    "        ##            lpVars.append(lp.LpVariable('W%i' % (i+1), None, None, lp.LpContinuous))\n",
    "        if not quiet:\n",
    "                print(\"Variables created\")\n",
    "        # objective function:\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)  # generator of experimental intensity observations\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars)), 'Dual_objective'\n",
    "        # constraints:\n",
    "        for j in range(k):\n",
    "                thr_vec = intensity_generator(thr_confs[j], global_mass_axis)\n",
    "                program += lp.lpSum(v*x for v, x in zip(thr_vec, lpVars) if v > 0.) <= 0, 'P%i' % (j+1)\n",
    "        if not quiet:\n",
    "                print('tsk tsk')\n",
    "        ##    for i in range(n-1):\n",
    "        ##        program += lpVars[i]-lpVars[i+1] <= interval_lengths[i], 'EpsPlus %i' % (i+1)\n",
    "        ##        program += lpVars[i] - lpVars[i+1] >=  -interval_lengths[i], 'EpsMinus %i' % (i+1)\n",
    "        for i in range(n-1):\n",
    "                program +=  lpVars[i] - lpVars[i+1]  <=  interval_lengths[i], 'EpsPlus_%i' % (i+1)\n",
    "                program +=  lpVars[i] - lpVars[i+1]  >= -interval_lengths[i], 'EpsMinus_%i' % (i+1)\n",
    "        if not quiet:\n",
    "                print(\"Constraints written\")\n",
    "        #program.writeLP('WassersteinL1.lp')\n",
    "        if not quiet:\n",
    "                print(\"Starting solver\")\n",
    "        LpSolverDefault.msg = not quiet\n",
    "        program.solve(solver = solver)\n",
    "        end = time()\n",
    "        if not quiet:\n",
    "                print(\"Solver finished.\")\n",
    "                print(\"Status:\", lp.LpStatus[program.status])\n",
    "                print(\"Optimal value:\", lp.value(program.objective))\n",
    "                print(\"Time:\", end - start)\n",
    "        constraints = program.constraints\n",
    "        probs = [round(constraints['P%i' % i].pi, 12) for i in range(1, k+1)]\n",
    "        exp_vec = list(intensity_generator(exp_confs, global_mass_axis))\n",
    "        # 'if' clause below is to restrict returned abyss to experimental confs\n",
    "        abyss = [round(x.dj, 12) for i, x in enumerate(lpVars) if exp_vec[i] > 0.]\n",
    "        # note: accounting for number of summands in checking of result correctness,\n",
    "        # because summation of many small numbers introduces numerical errors\n",
    "        if not np.isclose(sum(probs)+sum(abyss), 1., atol=len(abyss)*1e-03):\n",
    "                warn(\"\"\"In dualdeconv2:\n",
    "                Proportions of signal and noise sum to %f instead of 1.\n",
    "                This may indicate improper results.\n",
    "                Please check the deconvolution results and consider reporting this warning to the authors.\n",
    "                                    \"\"\" % (sum(probs)+sum(abyss)))\n",
    "\n",
    "        return {\"probs\": probs, \"trash\": abyss, \"fun\": lp.value(program.objective), 'status': program.status}\n",
    "\n",
    "\n",
    "def dualdeconv2_alternative(exp_sp, thr_sps, penalty, quiet=True, solver=LpSolverDefault):\n",
    "\n",
    "        \"\"\"\n",
    "        Alternative version of dualdeconv2 - using .pi instead of .dj to extract optimal values of variables.\n",
    "        Slower, but .pi is better documented than .dj in pulp. Gives the same results as dualdeconv2.\n",
    "        This function solves linear program describing optimal transport of signal between the experimental spectrum\n",
    "        and the list of theoretical (reference) spectra. Additionally, an auxiliary point is introduced in order to\n",
    "        remove noise from the experimental spectrum, as described by Ciach et al., 2020. \n",
    "        _____\n",
    "        Parameters:\n",
    "            exp_sp: Spectrum object\n",
    "                Experimental spectrum.\n",
    "            thr_sp: list of Spectrum objects\n",
    "                List of theoretical (reference) spectra.\n",
    "            penalty: float\n",
    "                Denoising penalty.\n",
    "            solver: \n",
    "                Which solver should be used. In case of problems with the default solver,\n",
    "                pulp.GUROBI() is recommended (note that it requires obtaining a licence).\n",
    "                To see all solvers available at your machine execute: pulp.listSolvers(onlyAvailable=True).\n",
    "        _____\n",
    "        Returns: dict\n",
    "            Dictionary with the following entries:\n",
    "            - probs: List containing proportions of consecutive theoretical (reference) spectra in the experimental\n",
    "            spectrum. Note that they do not have to sum up to 1, because some part of the signal can be noise.\n",
    "            - trash: Amount of noise in the consecutive m/z points of the experimental spectrum.\n",
    "            - fun: Optimal value of the objective function.\n",
    "            - status: Status of the linear program.\n",
    "        \"\"\"\n",
    "\n",
    "        start = time()\n",
    "        exp_confs = exp_sp.confs.copy()\n",
    "        thr_confs = [thr_sp.confs.copy() for thr_sp in thr_sps]\n",
    "\n",
    "        # Normalization check:\n",
    "        assert np.isclose(sum(x[1] for x in exp_confs) , 1), 'Experimental spectrum not normalized'\n",
    "        for i, thrcnf in enumerate(thr_confs):\n",
    "                assert np.isclose(sum(x[1] for x in thrcnf), 1), 'Theoretical spectrum %i not normalized' % i\n",
    "\n",
    "        # Computing a common mass axis for all spectra\n",
    "        exp_confs = [(m, i) for m, i in exp_confs]\n",
    "        thr_confs = [[(m, i) for m, i in cfs] for cfs in thr_confs]\n",
    "        global_mass_axis = set(x[0] for x in exp_confs)\n",
    "        global_mass_axis.update(x[0] for s in thr_confs for x in s)\n",
    "        global_mass_axis = sorted(global_mass_axis)\n",
    "        if not quiet:\n",
    "                print(\"Global mass axis computed\")\n",
    "        n = len(global_mass_axis)\n",
    "        k = len(thr_confs)\n",
    "\n",
    "        # Computing lengths of intervals between mz measurements (l_i variables)\n",
    "        interval_lengths = [global_mass_axis[i+1] - global_mass_axis[i] for i in range(n-1)]\n",
    "        if not quiet:\n",
    "                print(\"Interval lengths computed\")\n",
    "\n",
    "        # linear program:\n",
    "        program = lp.LpProblem('Dual_L1_regression_sparse', lp.LpMaximize)\n",
    "        if not quiet:\n",
    "                print(\"Linear program initialized\")\n",
    "        # variables:\n",
    "        lpVars = []\n",
    "        for i in range(n):\n",
    "                lpVars.append(lp.LpVariable('Z%i' % (i+1), None, None, lp.LpContinuous))\n",
    "        ##        # in case one would like to explicitly forbid non-experimental abyss:\n",
    "        ##        if V[i] > 0:\n",
    "        ##            lpVars.append(lp.LpVariable('W%i' % (i+1), None, penalty, lp.LpContinuous))\n",
    "        ##        else:\n",
    "        ##            lpVars.append(lp.LpVariable('W%i' % (i+1), None, None, lp.LpContinuous))\n",
    "        if not quiet:\n",
    "                print(\"Variables created\")\n",
    "        # objective function:\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)  # generator of experimental intensity observations\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars)), 'Dual_objective'\n",
    "        # constraints:\n",
    "        for j in range(k):\n",
    "                thr_vec = intensity_generator(thr_confs[j], global_mass_axis)\n",
    "                program += lp.lpSum(v*x for v, x in zip(thr_vec, lpVars) if v > 0.) <= 0, 'P%i' % (j+1)\n",
    "        if not quiet:\n",
    "                print('tsk tsk')\n",
    "        for i in range(n):\n",
    "                program += lpVars[i] <= penalty, 'g%i' % (i+1)\n",
    "        for i in range(n-1):\n",
    "                program +=  lpVars[i] - lpVars[i+1]  <=  interval_lengths[i], 'EpsPlus_%i' % (i+1)\n",
    "                program +=  lpVars[i] - lpVars[i+1]  >= -interval_lengths[i], 'EpsMinus_%i' % (i+1)\n",
    "        if not quiet:\n",
    "                print(\"Constraints written\")\n",
    "        #program.writeLP('WassersteinL1.lp')\n",
    "        if not quiet:\n",
    "                print(\"Starting solver\")\n",
    "        LpSolverDefault.msg = not quiet\n",
    "        program.solve(solver = solver)\n",
    "        end = time()\n",
    "        if not quiet:\n",
    "                print(\"Solver finished.\")\n",
    "                print(\"Status:\", lp.LpStatus[program.status])\n",
    "                print(\"Optimal value:\", lp.value(program.objective))\n",
    "                print(\"Time:\", end - start)\n",
    "        constraints = program.constraints\n",
    "        probs = [round(constraints['P%i' % i].pi, 12) for i in range(1, k+1)]\n",
    "        exp_vec = list(intensity_generator(exp_confs, global_mass_axis))\n",
    "        abyss = [round(constraints['g%i' % i].pi, 12) for i in range(1, n+1) if exp_vec[i-1] > 0.]\n",
    "        # note: accounting for number of summands in checking of result correctness,\n",
    "        # because summation of many small numbers introduces numerical errors\n",
    "        if not np.isclose(sum(probs)+sum(abyss), 1., atol=len(abyss)*1e-03):\n",
    "                warn(\"\"\"In dualdeconv2_alternative:\n",
    "                Proportions of signal and noise sum to %f instead of 1.\n",
    "                This may indicate improper results.\n",
    "                Please check the deconvolution results and consider reporting this warning to the authors.\n",
    "                                    \"\"\" % (sum(probs)+sum(abyss)))\n",
    "\n",
    "        return {\"probs\": probs, \"trash\": abyss, \"fun\": lp.value(program.objective), 'status': program.status}\n",
    "\n",
    "\n",
    "\n",
    "def dualdeconv3(exp_sp, thr_sps, penalty, penalty_th, quiet=True, solver=LpSolverDefault):\n",
    "\n",
    "        \"\"\"\n",
    "        This function solves linear program describing optimal transport of signal between \n",
    "        the experimental spectrum and the list of theoretical (reference) spectra. \n",
    "        Two auxiliary points are introduced in order to remove noise from the experimental spectrum\n",
    "        and from the combination of theoretical (reference) spectra, as described by Domżał et al., 2022. \n",
    "        Transport of signal between the two auxiliary points is explicitly forbidden.\n",
    "        Mathematically, this formulation is equivalent to the one implemented in dualdeconv4\n",
    "        and both give the same results up to roundoff errors.\n",
    "        _____\n",
    "        Parameters:\n",
    "            exp_sp: Spectrum object\n",
    "                Experimental spectrum.\n",
    "            thr_sp: Spectrum object\n",
    "                List of theoretical (reference) spectra.\n",
    "            penalty: float\n",
    "                Denoising penalty for the experimental spectrum.\n",
    "            penalty_th: float\n",
    "                Denoising penalty for the theoretical (reference) spectra.\n",
    "            solver: \n",
    "                Which solver should be used. In case of problems with the default solver,\n",
    "                pulp.GUROBI() is recommended (note that it requires obtaining a licence).\n",
    "                To see all solvers available at your machine execute: pulp.listSolvers(onlyAvailable=True).\n",
    "        _____\n",
    "        Returns: dict\n",
    "            Dictionary with the following entries:\n",
    "            - probs: List containing proportions of consecutive theoretical (reference) spectra in the experimental\n",
    "            spectrum. Note that they do not have to sum up to 1, because some part of the signal can be noise.\n",
    "            - noise_in_theoretical: Proportion of noise present in the combination of theoretical\n",
    "            (reference) spectra.\n",
    "            - trash: Amount of noise in the consecutive m/z points of the experimental spectrum.\n",
    "            - theoretical trash: Amount of noise present in the combination of theoretical (reference)\n",
    "            spectra in consecutive m/z points from global mass axis.\n",
    "            - fun: Optimal value of the objective function.\n",
    "            - status: Status of the linear program.\n",
    "            - global mass axis: All the m/z values from the experimental spectrum and from the theoretical \n",
    "            (reference) spectra in a sorted list. \n",
    "        \"\"\"\n",
    "\n",
    "        start = time()\n",
    "        exp_confs = exp_sp.confs.copy()\n",
    "        thr_confs = [thr_sp.confs.copy() for thr_sp in thr_sps]\n",
    "\n",
    "        # Normalization check:\n",
    "        assert np.isclose(sum(x[1] for x in exp_confs) , 1), 'Experimental spectrum not normalized'\n",
    "        for i, thrcnf in enumerate(thr_confs):\n",
    "                assert np.isclose(sum(x[1] for x in thrcnf), 1), 'Theoretical spectrum %i not normalized' % i\n",
    "\n",
    "        # Computing a common mass axis for all spectra\n",
    "        exp_confs = [(m, i) for m, i in exp_confs]\n",
    "        thr_confs = [[(m, i) for m, i in cfs] for cfs in thr_confs]\n",
    "        global_mass_axis = set(x[0] for x in exp_confs)\n",
    "        global_mass_axis.update(x[0] for s in thr_confs for x in s)\n",
    "        global_mass_axis = sorted(global_mass_axis)\n",
    "        if not quiet:\n",
    "                print(\"Global mass axis computed\")\n",
    "        n = len(global_mass_axis)\n",
    "        k = len(thr_confs)\n",
    "\n",
    "        # Computing lengths of intervals between mz measurements (l_i variables)\n",
    "        interval_lengths = [global_mass_axis[i+1] - global_mass_axis[i] for i in range(n-1)]\n",
    "        if not quiet:\n",
    "                print(\"Interval lengths computed\")\n",
    "\n",
    "        # linear program:\n",
    "        program = lp.LpProblem('Dual_L1_regression_sparse', lp.LpMaximize)\n",
    "        if not quiet:\n",
    "                print(\"Linear program initialized\")\n",
    "\n",
    "        # variables:\n",
    "        lpVars = []\n",
    "        try:\n",
    "                for i in range(n-2):\n",
    "                        lpVars.append(lp.LpVariable('Z%i' % (i+1), None, None, lp.LpContinuous))\n",
    "                lpVars.append(lp.LpVariable('Z%i' % (n-1), -interval_lengths[n-2], interval_lengths[n-2], lp.LpContinuous))\n",
    "        except IndexError:\n",
    "                pass\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n), None, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+1), None, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+2), 0, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+3), 0, None, lp.LpContinuous))\n",
    "\n",
    "        if not quiet:\n",
    "                print(\"Variables created\")\n",
    "\n",
    "        # objective function:\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)  # generator of experimental intensity observations\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars[:n-1]+[0])).addInPlace(\n",
    "                                lp.lpSum(v*x for v, x in zip([-1, 0, 0, -1], lpVars[n-1:]))), 'Dual_objective'\n",
    "\n",
    "        # constraints:\n",
    "        for j in range(k):\n",
    "                thr_vec = intensity_generator(thr_confs[j], global_mass_axis)\n",
    "                program += lp.lpSum(v*x for v, x in zip(thr_vec, lpVars[:n-1]+[0]) if v > 0.).addInPlace(\n",
    "                                lp.lpSum(v*x for v, x in zip([-1, 0, 1, -1], lpVars[n-1:]))) <= 0, 'P_%i' % (j+1)\n",
    "\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars[:n-1]+[0])).addInPlace(\n",
    "                                lp.lpSum(v*x for v, x in zip([0, 1, -1, 0], lpVars[n-1:]))) <= 0, 'p0_prime'\n",
    "\n",
    "        if not quiet:\n",
    "                print('tsk tsk')\n",
    "\n",
    "        for i in range(n-1):\n",
    "                program +=  lpVars[i] - lpVars[n-1]  <=  penalty, 'g_%i' % (i+1)\n",
    "                program +=  -lpVars[n] - lpVars[i] <= penalty_th, 'g_prime_%i' % (i+1)\n",
    "        try:\n",
    "                for i in range(n-2):\n",
    "                        program += lpVars[i] - lpVars[i+1] <= interval_lengths[i], 'epsilon_plus_%i' % (i+1)\n",
    "                        program += lpVars[i+1] - lpVars[i] <= interval_lengths[i], 'epsilon_minus_%i' % (i+1)\n",
    "        except IndexError:\n",
    "                pass\n",
    "\n",
    "        program += -lpVars[n-1] <= penalty, 'g_%i' % (n)\n",
    "        program += -lpVars[n] <= penalty_th, 'g_prime_%i' % (n)\n",
    "\n",
    "        if not quiet:\n",
    "                print(\"Constraints written\")\n",
    "\n",
    "        if not quiet:\n",
    "                print(\"Starting solver\")\n",
    "\n",
    "        #Solving\n",
    "        LpSolverDefault.msg = not quiet\n",
    "        program.solve(solver = solver)\n",
    "        end = time()\n",
    "        if not quiet:\n",
    "                print(\"Solver finished.\")\n",
    "                print(\"Status:\", lp.LpStatus[program.status])\n",
    "                print(\"Optimal value:\", lp.value(program.objective))\n",
    "                print(\"Time:\", end - start)\n",
    "        constraints = program.constraints\n",
    "        probs = [round(constraints['P_%i' % i].pi, 12) for i in range(1, k+1)]\n",
    "        p0_prime = round(constraints['p0_prime'].pi, 12)\n",
    "        exp_vec = list(intensity_generator(exp_confs, global_mass_axis))\n",
    "        abyss = [round(constraints['g_%i' % i].pi, 12) for i in range(1, n+1) if exp_vec[i-1] > 0.]\n",
    "        abyss_th = [round(constraints['g_prime_%i' % i].pi, 12) for i in range(1, n+1)]\n",
    "\n",
    "        if not np.isclose(sum(probs)+sum(abyss), 1., atol=len(abyss)*1e-03):\n",
    "                warn(\"\"\"In dualdeconv3:\n",
    "                Proportions of signal and noise sum to %f instead of 1.\n",
    "                This may indicate improper results.\n",
    "                Please check the deconvolution results and consider reporting this warning to the authors.\n",
    "                                    \"\"\" % (sum(probs)+sum(abyss)))\n",
    "\n",
    "        return {\"probs\": probs, \"noise_in_theoretical\": p0_prime, \"trash\": abyss, \"theoretical_trash\": abyss_th,\n",
    "         \"fun\": lp.value(program.objective), 'status': program.status, 'global_mass_axis': global_mass_axis}\n",
    "\n",
    "\n",
    "def dualdeconv4(exp_sp, thr_sps, penalty, penalty_th, quiet=True, solver=LpSolverDefault):\n",
    "\n",
    "        \"\"\"\n",
    "        This function solves linear program describing optimal transport of signal between the experimental \n",
    "        spectrum and the list of theoretical (reference) spectra. \n",
    "        Two auxiliary points are introduced in order to remove noise from the experimental spectrum\n",
    "        and from the combination of theoretical (reference) spectra, as described by Domżał et al., 2022. \n",
    "        Transport of signal between the two auxiliary points is allowed (with cost equal to penalty + penalty_th),\n",
    "        however, it is not optimal so it never occurs. Mathematically, this formulation is equivalent to the one \n",
    "        implemented in dualdeconv3 and both give the same results up to roundoff errors.\n",
    "        _____\n",
    "        Parameters:\n",
    "            exp_sp: Spectrum object\n",
    "                Experimental spectrum.\n",
    "            thr_sp: Spectrum object\n",
    "                List of theoretical (reference) spectra.\n",
    "            penalty: float\n",
    "                Denoising penalty for the experimental spectrum.\n",
    "            penalty_th: float\n",
    "                Denoising penalty for the theoretical (reference) spectra.\n",
    "            solver: \n",
    "                Which solver should be used. In case of problems with the default solver,\n",
    "                pulp.GUROBI() is recommended (note that it requires obtaining a licence).\n",
    "                To see all solvers available at your machine execute: pulp.listSolvers(onlyAvailable=True).\n",
    "        \n",
    "        _____\n",
    "        Returns: dict\n",
    "            Dictionary with the following entries:\n",
    "            - probs: List containing proportions of consecutive theoretical (reference) spectra in the experimental\n",
    "            spectrum. Note that they do not have to sum up to 1, because some part of the signal can be noise.\n",
    "            - noise_in_theoretical: Proportion of noise present in the combination of theoretical\n",
    "            (reference) spectra.\n",
    "            - trash: Amount of noise in the consecutive m/z points of the experimental spectrum.\n",
    "            - theoretical trash: Amount of noise present in the combination of theoretical (reference)\n",
    "            spectra in consecutive m/z points from global mass axis.\n",
    "            - fun: Optimal value of the objective function.\n",
    "            - status: Status of the linear program.\n",
    "            - global mass axis: All the m/z values from the experimental spectrum and from the theoretical \n",
    "            (reference) spectra in a sorted list. \n",
    "        \"\"\"\n",
    "\n",
    "        start = time()\n",
    "        exp_confs = exp_sp.confs.copy()\n",
    "        thr_confs = [thr_sp.confs.copy() for thr_sp in thr_sps]\n",
    "\n",
    "        # Normalization check:\n",
    "        assert np.isclose(sum(x[1] for x in exp_confs) , 1), 'Experimental spectrum not normalized'\n",
    "        for i, thrcnf in enumerate(thr_confs):\n",
    "                assert np.isclose(sum(x[1] for x in thrcnf), 1), 'Theoretical spectrum %i not normalized' % i\n",
    "\n",
    "        # Computing a common mass axis for all spectra\n",
    "        exp_confs = [(m, i) for m, i in exp_confs]\n",
    "        thr_confs = [[(m, i) for m, i in cfs] for cfs in thr_confs]\n",
    "        global_mass_axis = set(x[0] for x in exp_confs)\n",
    "        global_mass_axis.update(x[0] for s in thr_confs for x in s)\n",
    "        global_mass_axis = sorted(global_mass_axis)\n",
    "        if not quiet:\n",
    "                print(\"Global mass axis computed\")\n",
    "        n = len(global_mass_axis)\n",
    "        k = len(thr_confs)\n",
    "\n",
    "        # Computing lengths of intervals between mz measurements (l_i variables)\n",
    "        interval_lengths = [global_mass_axis[i+1] - global_mass_axis[i] for i in range(n-1)]\n",
    "        if not quiet:\n",
    "                print(\"Interval lengths computed\")\n",
    "\n",
    "        # linear program:\n",
    "        program = lp.LpProblem('Dual_L1_regression_sparse', lp.LpMaximize)\n",
    "        if not quiet:\n",
    "                print(\"Linear program initialized\")\n",
    "\n",
    "        # variables:\n",
    "        lpVars = []\n",
    "        try:\n",
    "                for i in range(n-2):\n",
    "                        lpVars.append(lp.LpVariable('Z%i' % (i+1), None, None, lp.LpContinuous))\n",
    "                lpVars.append(lp.LpVariable('Z%i' % (n-1), -interval_lengths[n-2], interval_lengths[n-2], lp.LpContinuous))\n",
    "        except IndexError:\n",
    "                pass\n",
    "        lpVars.append(lp.LpVariable('Z%i' % n, None, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+1), None, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+2), 0, None, lp.LpContinuous))\n",
    "        lpVars.append(lp.LpVariable('Z%i' % (n+3), 0, None, lp.LpContinuous))\n",
    "        if not quiet:\n",
    "                print(\"Variables created\")\n",
    "\n",
    "        # objective function:\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)  # generator of experimental intensity observations\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars[:n-1]+[0])).addInPlace(\n",
    "                            lp.lpSum(v*x for v, x in zip([-1, 0, 0, -1], lpVars[n-1:]))), 'Dual_objective'\n",
    "\n",
    "        # constraints:\n",
    "        for j in range(k):\n",
    "                thr_vec = intensity_generator(thr_confs[j], global_mass_axis)\n",
    "                program += lp.lpSum(v*x for v, x in zip(thr_vec, lpVars[:n-1]+[0]) if v > 0.).addInPlace(\n",
    "                            lp.lpSum(v*x for v, x in zip([-1, 0, 1, -1], lpVars[n-1:]))) <= -penalty, 'P_%i' % (j+1)\n",
    "\n",
    "        exp_vec = intensity_generator(exp_confs, global_mass_axis)\n",
    "        program += lp.lpSum(v*x for v, x in zip(exp_vec, lpVars[:n-1]+[0])).addInPlace(\n",
    "                            lp.lpSum(v*x for v, x in zip([0, 1, -1, 0], lpVars[n-1:]))) <= penalty_th, 'p0_prime'\n",
    "\n",
    "        if not quiet:\n",
    "                print('tsk tsk')\n",
    "        \n",
    "        for i in range(n-1):\n",
    "                program +=  lpVars[i] - lpVars[n-1]  <=  0, 'g_%i' % (i+1)\n",
    "                program +=  -lpVars[i] - lpVars[n]  <= 0, 'g_prime_%i' % (i+1)\n",
    "        try:\n",
    "                for i in range(n-2):\n",
    "                        program += lpVars[i] - lpVars[i+1] <= interval_lengths[i], 'epsilon_plus_%i' % (i+1)\n",
    "                        program += lpVars[i+1] - lpVars[i] <= interval_lengths[i], 'epsilon_minus_%i' % (i+1)\n",
    "        except IndexError:\n",
    "                pass\n",
    "\n",
    "        program += -lpVars[n-1] <= 0, 'g_%i' % (n)\n",
    "        program += -lpVars[n] <= 0, 'g_prime_%i' % (n)\n",
    "\n",
    "        if not quiet:\n",
    "                print(\"Constraints written\")\n",
    "\n",
    "        if not quiet:\n",
    "                print(\"Starting solver\")\n",
    "\n",
    "        #Solving\n",
    "        LpSolverDefault.msg = not quiet\n",
    "        program.solve(solver = solver)\n",
    "        end = time()\n",
    "        if not quiet:\n",
    "                print(\"Solver finished.\")\n",
    "                print(\"Status:\", lp.LpStatus[program.status])\n",
    "                print(\"Optimal value:\", lp.value(program.objective))\n",
    "                print(\"Time:\", end - start)\n",
    "        constraints = program.constraints\n",
    "        probs = [round(constraints['P_%i' % i].pi, 12) for i in range(1, k+1)]\n",
    "        p0_prime = round(constraints['p0_prime'].pi, 12)\n",
    "        exp_vec = list(intensity_generator(exp_confs, global_mass_axis))\n",
    "        abyss = [round(constraints['g_%i' % i].pi, 12) for i in range(1, n+1) if exp_vec[i-1] > 0.]\n",
    "        abyss_th = [round(constraints['g_prime_%i' % i].pi, 12) for i in range(1, n+1)]\n",
    "        if not np.isclose(sum(probs)+sum(abyss), 1., atol=len(abyss)*1e-03):\n",
    "                warn(\"\"\"In dualdeconv4:\n",
    "                Proportions of signal and noise sum to %f instead of 1.\n",
    "                This may indicate improper results.\n",
    "                Please check the deconvolution results and consider reporting this warning to the authors.\n",
    "                                    \"\"\" % (sum(probs)+sum(abyss)))\n",
    "\n",
    "        return {\"probs\": probs, \"noise_in_theoretical\": p0_prime, \"trash\": abyss, \"theoretical_trash\": abyss_th, \n",
    "        \"fun\": lp.value(program.objective)+penalty, 'status': program.status, 'global_mass_axis': global_mass_axis}\n",
    "\n",
    "\n",
    "def estimate_proportions(spectrum, query, MTD=0.1, MDC=1e-8,\n",
    "                        MMD=-1, max_reruns=3, verbose=False, \n",
    "                        progress=True, MTD_th=None, solver=LpSolverDefault):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns estimated proportions of molecules from query in spectrum.\n",
    "    Performs initial filtering of formulas and experimental spectrum to speed up the computations.\n",
    "    _____\n",
    "    Parameters:\n",
    "    spectrum: Spectrum object\n",
    "        The experimental (subject) spectrum.\n",
    "    query: list of Spectrum objects\n",
    "        A list of theoretical (reference) spectra.\n",
    "    MTD: Maximum Transport Distance, float\n",
    "        Ion current from experimental spectrum will be transported up to this distance when estimating\n",
    "        molecule proportions. Default is 1.\n",
    "    MDC: Minimum Detectable Current, float\n",
    "        If the isotopic envelope of an ion encompasses less than\n",
    "        this amount of the total ion current, it is assumed that this ion\n",
    "        is absent in the spectrum. Default is 1e-8.\n",
    "    MMD: Maximum Mode Distance, float\n",
    "        If there is no experimental peak within this distance from the\n",
    "        highest peak of an isotopic envelope of a molecule,\n",
    "        it is assumed that this molecule is absent in the spectrum.\n",
    "        Setting this value to -1 disables filtering. Default is -1.\n",
    "    max_reruns: int\n",
    "        Due to numerical errors, some partial results may be inaccurate.\n",
    "        If this is detected, then those results are recomputed for a maximal number of times\n",
    "        given by this parameter. Default is 3.\n",
    "    verbose: bool\n",
    "        Print diagnistic messages? Default is False.\n",
    "    progress: bool\n",
    "        Whether to display progress bars during work. Default is True.\n",
    "    MTD_th: Maximum Transport Distance for theoretical spectra, float\n",
    "        If presence of noise in theoretical (reference, query) spectra is not expected, \n",
    "        then this parameter should be set to None. Otherwise, set its value to some positive real number.\n",
    "        Ion current from theoretical spectra will be transported up to this distance \n",
    "        when estimating molecule proportions. Default is None.\n",
    "    solver: \n",
    "        Which solver should be used. In case of problems with the default solver,\n",
    "        pulp.GUROBI() is recommended (note that it requires obtaining a licence).\n",
    "        To see all solvers available at your machine execute: pulp.listSolvers(onlyAvailable=True).\n",
    "    _____\n",
    "    Returns: dict\n",
    "        A dictionary with the following entries:\n",
    "        - proportions: List of proportions of query (i.e. theoretical, reference) spectra.\n",
    "        - noise: List of intensities that could not be explained by the supplied formulas. \n",
    "        The intensities correspond to the m/z values of the experimental spectrum.\n",
    "        If MTD_th parameter is not equal to None, then the dictionary contains also \n",
    "        the following entries:\n",
    "        - noise_in_theoretical: List of intensities from query (i.e. theoretical, reference) spectra\n",
    "        that do not correspond to any intensities in the experimental spectrum and therefore were \n",
    "        identified as noise. The intensities correspond to the m/z values from global mass axis.\n",
    "        - proportion_of_noise_in_theoretical: Proportion of noise present in the combination of query\n",
    "        (i.e. theoretical, reference) spectra.\n",
    "        - global_mass_axis: All the m/z values from the experimental spectrum and from the query \n",
    "        (i.e. theoretical, reference) spectra in a sorted list. \n",
    "    \"\"\"\n",
    "\n",
    "    def progr_bar(x, **kwargs):\n",
    "        if progress:\n",
    "            return tqdm(x, **kwargs)\n",
    "        else:\n",
    "            return x\n",
    "    try:\n",
    "        exp_confs = spectrum.confs\n",
    "    except:\n",
    "        print(\"Could not retrieve the confs list. Is the supplied spectrum an object of class Spectrum?\")\n",
    "        raise\n",
    "    assert abs(sum(x[1] for x in exp_confs) - 1.) < 1e-08, 'The experimental spectrum is not normalized.'\n",
    "    #assert all(x[0] >= 0. for x in exp_confs), 'Found experimental peaks with negative masses!'\n",
    "    if any(x[1] < 0 for x in exp_confs):\n",
    "        raise ValueError(\"\"\"\n",
    "        The experimental spectrum cannot contain negative intensities. \n",
    "        Please remove them using e.g. the Spectrum.trim_negative_intensities() method.\n",
    "        \"\"\")\n",
    "                           \n",
    "    vortex = [0.]*len(exp_confs)  # unexplained signal\n",
    "    k = len(query)\n",
    "    proportions = [0.]*k\n",
    "\n",
    "    if MTD_th is None:\n",
    "        MTD_max = MTD\n",
    "    else:\n",
    "        MTD_max = max(MTD, MTD_th)\n",
    "\n",
    "    for i, q in enumerate(query):\n",
    "        assert abs(sum(x[1] for x in q.confs) - 1.) < 1e-08, 'Theoretical spectrum %i is not normalized' %i\n",
    "        #assert all(x[0] >= 0 for x in q.confs), 'Theoretical spectrum %i has negative masses!' % i\n",
    "\n",
    "    # Initial filtering of formulas\n",
    "    envelope_bounds = []\n",
    "    filtered = []\n",
    "    for i in progr_bar(range(k), desc = \"Initial filtering of formulas\"):\n",
    "        s = query[i]\n",
    "        mode = s.get_modal_peak()[0]\n",
    "        mn = s.confs[0][0]\n",
    "        mx = s.confs[-1][0]\n",
    "        matching_current = MDC==0. or sum(x[1] for x in misc.extract_range(\n",
    "                                                                        exp_confs, mn - MTD_max, mx + MTD_max)) >= MDC\n",
    "        matching_mode = MMD==-1 or abs(misc.closest(exp_confs, mode)[0] - mode) <= MMD\n",
    "\n",
    "        if matching_mode and matching_current:\n",
    "            envelope_bounds.append((mn, mx, i))\n",
    "        else:\n",
    "            envelope_bounds.append((-1, -1, i))\n",
    "            filtered.append(i)\n",
    "\n",
    "    envelope_bounds.sort(key=lambda x: x[0])  # sorting by lower bounds\n",
    "    if verbose:\n",
    "        print(\"Removed theoretical spectra due to no matching experimental peaks:\", filtered)\n",
    "        print('Envelope bounds:', envelope_bounds)\n",
    "\n",
    "    # Computing chunks\n",
    "    chunkIDs = [0]*k  # Grouping of theoretical spectra\n",
    "    # Note: order of chunkIDs corresponds to order of query, not the envelope bounds\n",
    "    # chunk_bounds = mass intervals matching chunks, accounting for mass transport\n",
    "    # order of chunk_bounds corresponds to increasing chunk ID,\n",
    "    # so that chunk_bounds[0] is the interval for chunk nr 0\n",
    "    chunk_bounds = []\n",
    "    current_chunk = 0\n",
    "    first_present = 0\n",
    "    while envelope_bounds[first_present][0] == -1 and first_present < k-1:\n",
    "        _, _, sp_id = envelope_bounds[first_present]\n",
    "        chunkIDs[sp_id] = -1\n",
    "        first_present += 1\n",
    "    prev_mn, prev_mx, prev_id = envelope_bounds[first_present]\n",
    "    for i in progr_bar(range(first_present, k), desc = \"Computing chunks\"):\n",
    "        mn, mx, sp_id = envelope_bounds[i]\n",
    "        if mn - prev_mx > 2*MTD_max:\n",
    "            current_chunk += 1\n",
    "            chunk_bounds.append( (prev_mn-MTD_max, prev_mx+MTD_max) )\n",
    "            prev_mn = mn  # get lower bound of new chunk\n",
    "        prev_mx = mx  # update the lower bound of current chunk\n",
    "        chunkIDs[sp_id] = current_chunk\n",
    "    chunk_bounds.append( (prev_mn-MTD_max, prev_mx+MTD_max) )\n",
    "    nb_of_chunks = len(chunk_bounds)\n",
    "    if verbose:\n",
    "        print('Number of chunks: %i' % nb_of_chunks)\n",
    "        print(\"ChunkIDs:\", chunkIDs)\n",
    "        print(\"Chunk bounds:\", chunk_bounds)\n",
    "\n",
    "    # Splitting the experimental spectrum into chunks\n",
    "    exp_conf_chunks = []  # list of indices of experimental confs matching chunks\n",
    "    current_chunk = 0\n",
    "    matching_confs = []  # experimental confs matching current chunk\n",
    "    cur_bound = chunk_bounds[current_chunk]\n",
    "    for conf_id, cur_conf in progr_bar(enumerate(exp_confs), desc = \"Splitting the experimental spectrum into chunks\"):\n",
    "        while cur_bound[1] < cur_conf[0] and current_chunk < nb_of_chunks-1:\n",
    "            exp_conf_chunks.append(matching_confs)\n",
    "            matching_confs = []\n",
    "            current_chunk += 1\n",
    "            cur_bound = chunk_bounds[current_chunk]\n",
    "        if cur_bound[0] <= cur_conf[0] <= cur_bound[1]:\n",
    "            matching_confs.append(conf_id)\n",
    "        else:\n",
    "            # experimental peaks outside chunks go straight to vortex\n",
    "            vortex[conf_id] = cur_conf[1]\n",
    "    exp_conf_chunks.append(matching_confs)\n",
    "    chunk_TICs = [sum(exp_confs[i][1] for i in chunk_list) for chunk_list in exp_conf_chunks]\n",
    "    if verbose:\n",
    "        # print('Trash after filtering:', vortex)\n",
    "        print(\"Ion currents in chunks:\", chunk_TICs)\n",
    "\n",
    "    # Deconvolving chunks:\n",
    "    p0_prime = 0\n",
    "    vortex_th = []\n",
    "    global_mass_axis = []\n",
    "    for current_chunk_ID, conf_IDs in progr_bar(enumerate(exp_conf_chunks), desc=\"Deconvolving chunks\", \n",
    "                                                                            total=len(exp_conf_chunks)):\n",
    "        if verbose:\n",
    "            print(\"Deconvolving chunk %i\" % current_chunk_ID)\n",
    "        if chunk_TICs[current_chunk_ID] < 1e-16:\n",
    "            # nothing to deconvolve, pushing remaining signal to vortex\n",
    "            if verbose:\n",
    "                print('Chunk %i is almost empty - skipping deconvolution' % current_chunk_ID)\n",
    "            for i in conf_IDs:\n",
    "                vortex[i] = exp_confs[i][1]\n",
    "        else:\n",
    "            chunkSp = Spectrum('', empty=True)\n",
    "            # Note: conf_IDs are monotonic w.r.t. conf mass,\n",
    "            # so constructing a spectrum will not change the order\n",
    "            # of confs supplied in the list below:\n",
    "            chunkSp.set_confs([exp_confs[i] for i in conf_IDs])\n",
    "            chunkSp.normalize()\n",
    "            theoretical_spectra_IDs = [i for i, c in enumerate(chunkIDs) if c == current_chunk_ID]\n",
    "            thrSp = [query[i] for i in theoretical_spectra_IDs]\n",
    "\n",
    "            rerun = 0\n",
    "            success = False\n",
    "            while not success:\n",
    "                    rerun += 1\n",
    "                    if rerun > max_reruns:\n",
    "                            raise RuntimeError('Failed to deconvolve a fragment of the experimental spectrum \\\n",
    "                                                with mass (%f, %f)' % chunk_bounds[current_chunk_ID])\n",
    "                    if MTD_th is None:\n",
    "                        dec = dualdeconv2(chunkSp, thrSp, MTD, quiet=True, solver=solver)\n",
    "                    else:\n",
    "                        dec = dualdeconv4(chunkSp, thrSp, MTD, MTD_th, quiet=True, solver=solver)\n",
    "                    if dec['status'] == 1:\n",
    "                            success=True\n",
    "                    else:\n",
    "                            warn('Rerunning computations for chunk %i due to status %s' % (current_chunk_ID, \n",
    "                                                                                        lp.LpStatus[dec['status']]))\n",
    "            if verbose:\n",
    "                    print('Chunk %i deconvolution status:', lp.LpStatus[dec['status']])\n",
    "                    print('Signal proportion in experimental spectrum:', sum(dec['probs']))\n",
    "                    print('Noise proportion in experimental spectrum:', sum(dec['trash']))\n",
    "                    print('Total explanation:', sum(dec['probs'])+sum(dec['trash']))\n",
    "                    if MTD_th is not None:\n",
    "                        print('Noise proportion in combination of theoretical spectra:', dec[\"noise_in_theoretical\"])\n",
    "            for i, p in enumerate(dec['probs']):\n",
    "                original_thr_spectrum_ID = theoretical_spectra_IDs[i]\n",
    "                proportions[original_thr_spectrum_ID] = p*chunk_TICs[current_chunk_ID]\n",
    "            for i, p in enumerate(dec['trash']):\n",
    "                original_conf_id = conf_IDs[i]\n",
    "                vortex[original_conf_id] = p*chunk_TICs[current_chunk_ID]\n",
    "            if MTD_th is not None:\n",
    "                p0_prime = p0_prime + dec[\"noise_in_theoretical\"]*chunk_TICs[current_chunk_ID]\n",
    "                rescaled_vortex_th = [element*chunk_TICs[current_chunk_ID] for element in dec['theoretical_trash']]\n",
    "                vortex_th = vortex_th + rescaled_vortex_th\n",
    "                global_mass_axis = global_mass_axis + dec['global_mass_axis']\n",
    "\n",
    "    if not np.isclose(sum(proportions)+sum(vortex), 1., atol=len(vortex)*1e-03):\n",
    "        warn(\"\"\"In estimate_proportions:\n",
    "Proportions of signal and noise sum to %f instead of 1.\n",
    "This may indicate improper results.\n",
    "Please check the deconvolution results and consider reporting this warning to the authors.\n",
    "                        \"\"\" % (sum(proportions)+sum(vortex)))\n",
    "    if MTD_th is not None:\n",
    "        return {'proportions': proportions, 'noise': vortex, 'noise_in_theoretical': vortex_th, \n",
    "                'proportion_of_noise_in_theoretical': p0_prime, 'global_mass_axis': global_mass_axis}\n",
    "    else:\n",
    "        return {'proportions': proportions, 'noise': vortex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33224ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = np.loadtxt('preprocessed_mix.csv', delimiter=',')\n",
    "comp0_p = np.loadtxt('preprocessed_comp0.csv', delimiter=',')\n",
    "comp1_p = np.loadtxt('preprocessed_comp1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84dbe493",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_p = Spectrum(confs=list(zip(mix_p[:,0], mix_p[:,1])))\n",
    "comp0_p = Spectrum(confs=list(zip(comp0_p[:,0], comp0_p[:,1])))\n",
    "comp1_p = Spectrum(confs=list(zip(comp1_p[:,0], comp1_p[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1c7cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial filtering of formulas: 100%|██████████████| 2/2 [00:00<00:00, 62.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed theoretical spectra due to no matching experimental peaks: []\n",
      "Envelope bounds: [(-1.97165, 13.9718, 0), (-1.97165, 13.9718, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing chunks: 100%|████████████████████████| 2/2 [00:00<00:00, 91180.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "ChunkIDs: [0, 0]\n",
      "Chunk bounds: [(-2.20165, 14.2018)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting the experimental spectrum into chunks: 131072it [00:00, 3388283.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ion currents in chunks: [1.000000000000015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Deconvolving chunks:   0%|                                | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deconvolving chunks: 100%|███████████████████████| 1/1 [03:03<00:00, 183.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk %i deconvolution status: Optimal\n",
      "Signal proportion in experimental spectrum: 0.983121176726\n",
      "Noise proportion in experimental spectrum: 0.016878823246000003\n",
      "Total explanation: 0.999999999972\n",
      "Noise proportion in combination of theoretical spectra: 0.240669939935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = estimate_proportions(mix_p, [comp0_p, comp1_p],\n",
    "                                   MTD=0.23, MTD_th=0.02, verbose=True, solver=pulp.GUROBI(msg=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f28f649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24066993993500363"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation['proportion_of_noise_in_theoretical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be09dba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.2406736130420037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d14f5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(estimation['proportion_of_noise_in_theoretical'], 0.24066993993500363)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297bc7b0",
   "metadata": {},
   "source": [
    "The result is the same as for spectrum without shift and magnetstein. So everything is ok."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
